{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e8199f",
   "metadata": {
    "papermill": {
     "duration": 0.00769,
     "end_time": "2022-10-08T10:43:03.668694",
     "exception": false,
     "start_time": "2022-10-08T10:43:03.661004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2527926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:03.685984Z",
     "iopub.status.busy": "2022-10-08T10:43:03.685442Z",
     "iopub.status.idle": "2022-10-08T10:43:09.397086Z",
     "shell.execute_reply": "2022-10-08T10:43:09.396109Z"
    },
    "papermill": {
     "duration": 5.723329,
     "end_time": "2022-10-08T10:43:09.399657",
     "exception": false,
     "start_time": "2022-10-08T10:43:03.676328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAvgPool2D, BatchNormalization\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37b591",
   "metadata": {
    "papermill": {
     "duration": 0.007007,
     "end_time": "2022-10-08T10:43:09.413458",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.406451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e6593",
   "metadata": {
    "papermill": {
     "duration": 0.006266,
     "end_time": "2022-10-08T10:43:09.426250",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.419984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A detailed discussion and visualization of the data can be seen in [here](Data-Overview.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0cf188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:09.441315Z",
     "iopub.status.busy": "2022-10-08T10:43:09.440651Z",
     "iopub.status.idle": "2022-10-08T10:43:09.478911Z",
     "shell.execute_reply": "2022-10-08T10:43:09.477928Z"
    },
    "papermill": {
     "duration": 0.048431,
     "end_time": "2022-10-08T10:43:09.481297",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.432866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../input/datathonindoml-2022/train_labels.csv\")\n",
    "images = ['../input/datathonindoml-2022/train/train/'+str(name)+'.tif' for name in labels['id']]\n",
    "labels['images'] = images\n",
    "labels = labels[['id', 'images', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7bcd32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:09.497277Z",
     "iopub.status.busy": "2022-10-08T10:43:09.496852Z",
     "iopub.status.idle": "2022-10-08T10:43:09.518550Z",
     "shell.execute_reply": "2022-10-08T10:43:09.517527Z"
    },
    "papermill": {
     "duration": 0.032617,
     "end_time": "2022-10-08T10:43:09.520779",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.488162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>images</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/0.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/1.tif</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/2.tif</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/3.tif</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/4.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>15995</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/15995...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>15996</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/15996...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>15997</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/15997...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>15998</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/15998...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>15999</td>\n",
       "      <td>../input/datathonindoml-2022/train/train/15999...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                             images  label\n",
       "0          0     ../input/datathonindoml-2022/train/train/0.tif      1\n",
       "1          1     ../input/datathonindoml-2022/train/train/1.tif     13\n",
       "2          2     ../input/datathonindoml-2022/train/train/2.tif     13\n",
       "3          3     ../input/datathonindoml-2022/train/train/3.tif     14\n",
       "4          4     ../input/datathonindoml-2022/train/train/4.tif      6\n",
       "...      ...                                                ...    ...\n",
       "15995  15995  ../input/datathonindoml-2022/train/train/15995...      2\n",
       "15996  15996  ../input/datathonindoml-2022/train/train/15996...     15\n",
       "15997  15997  ../input/datathonindoml-2022/train/train/15997...      3\n",
       "15998  15998  ../input/datathonindoml-2022/train/train/15998...      9\n",
       "15999  15999  ../input/datathonindoml-2022/train/train/15999...      9\n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c491c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:09.536871Z",
     "iopub.status.busy": "2022-10-08T10:43:09.535357Z",
     "iopub.status.idle": "2022-10-08T10:43:09.543355Z",
     "shell.execute_reply": "2022-10-08T10:43:09.542447Z"
    },
    "papermill": {
     "duration": 0.017683,
     "end_time": "2022-10-08T10:43:09.545395",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.527712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = list(set(labels['label']))\n",
    "class_names = [\n",
    "    'letter', 'form', 'email', 'handwritten', 'advertisement', 'scientific report', 'scientific publication',\n",
    "    'specification', 'file folder', 'news article', 'budget', 'invoice', 'presentation', 'questionnaire', 'resume',\n",
    "    'memo'\n",
    "]\n",
    "label_names = pd.DataFrame({\n",
    "    'labels': class_labels,\n",
    "    'names': class_names\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d432b",
   "metadata": {
    "papermill": {
     "duration": 0.006408,
     "end_time": "2022-10-08T10:43:09.558441",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.552033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78222fbd",
   "metadata": {
    "papermill": {
     "duration": 0.006344,
     "end_time": "2022-10-08T10:43:09.571326",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.564982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since, there is a lot of image data instead of using the whole data at once in a tensor form, we would be using a data generator to prevent memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce26c32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:09.587260Z",
     "iopub.status.busy": "2022-10-08T10:43:09.585652Z",
     "iopub.status.idle": "2022-10-08T10:43:12.739568Z",
     "shell.execute_reply": "2022-10-08T10:43:12.738052Z"
    },
    "papermill": {
     "duration": 3.164731,
     "end_time": "2022-10-08T10:43:12.742569",
     "exception": false,
     "start_time": "2022-10-08T10:43:09.577838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 10:43:10.137729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:10.217189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:10.218003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Image Height: 1000.0\n",
      "Mean Image Width: 765.0\n",
      "Min Image Height: 1000\n",
      "Min Image Width: 754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 10:43:10.221883: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-08 10:43:10.222280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:10.223265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:10.224082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:12.306169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:12.307013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:12.307739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:43:12.308356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "imgs = [tf.cast(img_to_array(load_img('../input/datathonindoml-2022/validation/validation/'+name)), dtype=tf.uint8) for name in os.listdir('../input/datathonindoml-2022/validation/validation')[:4]]\n",
    "heights = [img.shape[0] for img in imgs]\n",
    "widths = [img.shape[1] for img in imgs]\n",
    "print(\"\")\n",
    "print(\"Mean Image Height:\", np.mean(heights))\n",
    "print(\"Mean Image Width:\", np.mean(widths))\n",
    "print(\"Min Image Height:\", np.min(heights))\n",
    "print(\"Min Image Width:\", np.min(widths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c8101",
   "metadata": {
    "papermill": {
     "duration": 0.006672,
     "end_time": "2022-10-08T10:43:12.757017",
     "exception": false,
     "start_time": "2022-10-08T10:43:12.750345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Observing the average image heights and widths, it is observed that setting image height to $1000$ and image width to $750$ is reseonable for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea48c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:12.773290Z",
     "iopub.status.busy": "2022-10-08T10:43:12.771603Z",
     "iopub.status.idle": "2022-10-08T10:43:12.777958Z",
     "shell.execute_reply": "2022-10-08T10:43:12.777089Z"
    },
    "papermill": {
     "duration": 0.016418,
     "end_time": "2022-10-08T10:43:12.780140",
     "exception": false,
     "start_time": "2022-10-08T10:43:12.763722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "INPUT_SHAPE = (800, 600) # Full Image\n",
    "INPUT_HDR_SHAPE = INPUT_FTR_SHAPE = (250, 600)\n",
    "INPUT_BDL_SHAPE = INPUT_BDR_SHAPE = (300, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e00fcf",
   "metadata": {
    "papermill": {
     "duration": 0.0066,
     "end_time": "2022-10-08T10:43:12.793629",
     "exception": false,
     "start_time": "2022-10-08T10:43:12.787029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since, the Keras' own data generator does not support TIFF images, we resort to writing our own custom data generator. It can also be leveraged to put custom image pre-processing or multi-input or output in the data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b4e976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:12.808788Z",
     "iopub.status.busy": "2022-10-08T10:43:12.808456Z",
     "iopub.status.idle": "2022-10-08T10:43:12.822033Z",
     "shell.execute_reply": "2022-10-08T10:43:12.821126Z"
    },
    "papermill": {
     "duration": 0.023603,
     "end_time": "2022-10-08T10:43:12.823963",
     "exception": false,
     "start_time": "2022-10-08T10:43:12.800360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, X_col, y_col, batch_size, input_size=(800, 600), shuffle=True):\n",
    "        self.df = df.copy() # DataFrame consisting image paths of inputs and the labels for the outputs\n",
    "        self.X_col = X_col # Input column, specifying image path, in the DataFrame\n",
    "        self.y_col = y_col # Output column, specifying corresponding label, in the DataFrame\n",
    "        self.batch_size = batch_size # Batch Size\n",
    "        self.input_size = input_size # Input Image size\n",
    "        self.shuffle = shuffle # Shuffle Data after each epoch\n",
    "        self.n = len(self.df) # length of the entire data\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        img_arr = img_to_array(load_img(path))\n",
    "        # some other pre-processing / data-augmentation goes here\n",
    "        img_arr = tf.image.resize(img_arr, self.input_size)\n",
    "        img_hdr, img_bdl, img_bdr, img_ftr = img_arr[:250], img_arr[250:-250, :300], img_arr[250:-250, -300:], img_arr[-250:]\n",
    "        return [preprocess_input(img_hdr), preprocess_input(img_bdl), preprocess_input(img_bdr), preprocess_input(img_ftr), preprocess_input(img_arr)]\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        batch_paths = batches[self.X_col]\n",
    "        batch_labels = batches[self.y_col]\n",
    "        X_batch_4 = [self.__get_input(path) for path in batch_paths]\n",
    "        X_batch = tf.cast([img[0] for img in X_batch_4], dtype=tf.float32), tf.cast([img[1] for img in X_batch_4], dtype=tf.float32), tf.cast([img[2] for img in X_batch_4], dtype=tf.float32), tf.cast([img[3] for img in X_batch_4], dtype=tf.float32), tf.cast([img[4] for img in X_batch_4], dtype=tf.float32)\n",
    "        y_batch = tf.cast(batch_labels, dtype=tf.float32)\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44fb7a80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:12.839220Z",
     "iopub.status.busy": "2022-10-08T10:43:12.838878Z",
     "iopub.status.idle": "2022-10-08T10:43:12.844314Z",
     "shell.execute_reply": "2022-10-08T10:43:12.843253Z"
    },
    "papermill": {
     "duration": 0.015488,
     "end_time": "2022-10-08T10:43:12.846409",
     "exception": false,
     "start_time": "2022-10-08T10:43:12.830921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    df=labels,\n",
    "    X_col='images',\n",
    "    y_col='label',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    input_size=INPUT_SHAPE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2ae41",
   "metadata": {
    "papermill": {
     "duration": 0.006701,
     "end_time": "2022-10-08T10:43:12.860081",
     "exception": false,
     "start_time": "2022-10-08T10:43:12.853380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below shows one batch from the ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be59abe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:12.876976Z",
     "iopub.status.busy": "2022-10-08T10:43:12.875101Z",
     "iopub.status.idle": "2022-10-08T10:43:13.564677Z",
     "shell.execute_reply": "2022-10-08T10:43:13.563205Z"
    },
    "papermill": {
     "duration": 0.703164,
     "end_time": "2022-10-08T10:43:13.570184",
     "exception": false,
     "start_time": "2022-10-08T10:43:12.867020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Batch Overview ***\n",
      "Number of Inputs: 5\n",
      "Input Image Header Tensor Shape: (40, 250, 600, 3)\n",
      "Input Image Body(L) Tensor Shape: (40, 300, 300, 3)\n",
      "Input Image Body(R) Tensor Shape: (40, 300, 300, 3)\n",
      "Input Image Footer Tensor Shape: (40, 250, 600, 3)\n",
      "Input Image Full Tensor Shape: (40, 800, 600, 3)\n",
      "Output Label Tensor Shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_generator))\n",
    "print('*** Batch Overview ***')\n",
    "print('Number of Inputs:', len(batch[0]))\n",
    "print('Input Image Header Tensor Shape:', batch[0][0].shape)\n",
    "print('Input Image Body(L) Tensor Shape:', batch[0][1].shape)\n",
    "print('Input Image Body(R) Tensor Shape:', batch[0][2].shape)\n",
    "print('Input Image Footer Tensor Shape:', batch[0][3].shape)\n",
    "print('Input Image Full Tensor Shape:', batch[0][4].shape)\n",
    "print('Output Label Tensor Shape:', batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b4fb8",
   "metadata": {
    "papermill": {
     "duration": 0.006821,
     "end_time": "2022-10-08T10:43:13.588547",
     "exception": false,
     "start_time": "2022-10-08T10:43:13.581726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each row below shows the $4$ parts of the same image and the full image, where the first being the header, second being the body(left), third is body(right) and last one is footer and the full image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c740533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:13.603686Z",
     "iopub.status.busy": "2022-10-08T10:43:13.603339Z",
     "iopub.status.idle": "2022-10-08T10:43:13.609012Z",
     "shell.execute_reply": "2022-10-08T10:43:13.608115Z"
    },
    "papermill": {
     "duration": 0.015526,
     "end_time": "2022-10-08T10:43:13.610923",
     "exception": false,
     "start_time": "2022-10-08T10:43:13.595397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(BATCH_SIZE//2, 5, figsize=(12, 60))\n",
    "# imgs = batch[0]\n",
    "# labs = list(batch[1].numpy())\n",
    "# for j in range(BATCH_SIZE//2):\n",
    "#     for k in range(5):\n",
    "#         ax[j, k].imshow((imgs[k][j]*255).numpy().astype(np.uint8))\n",
    "#         ax[j, k].axis('off')\n",
    "#         ax[j, k].set_title(labs[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c63f9",
   "metadata": {
    "papermill": {
     "duration": 0.006731,
     "end_time": "2022-10-08T10:43:13.624704",
     "exception": false,
     "start_time": "2022-10-08T10:43:13.617973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f78114",
   "metadata": {
    "papermill": {
     "duration": 0.006564,
     "end_time": "2022-10-08T10:43:13.638038",
     "exception": false,
     "start_time": "2022-10-08T10:43:13.631474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, a basic CNN-based model will be put to place. It will utilize the visual features only to classify the documents. Later we will be building much more better models considering other structures and multi-modality of the images and distinctive features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d721237",
   "metadata": {
    "papermill": {
     "duration": 0.006555,
     "end_time": "2022-10-08T10:43:13.651480",
     "exception": false,
     "start_time": "2022-10-08T10:43:13.644925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- ResNet50V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac30f11",
   "metadata": {
    "papermill": {
     "duration": 0.006614,
     "end_time": "2022-10-08T10:43:13.664878",
     "exception": false,
     "start_time": "2022-10-08T10:43:13.658264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The ResNet50V2 is a large model and since, we are not pre-training the entire model, we will just fine-tune it with two extra layers. So, to fasten training we precompute the output of the ResNet50V2 model and use this for training the added Dense Layers for Fine-Tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4547ab64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:13.681428Z",
     "iopub.status.busy": "2022-10-08T10:43:13.679715Z",
     "iopub.status.idle": "2022-10-08T10:43:19.559159Z",
     "shell.execute_reply": "2022-10-08T10:43:19.558142Z"
    },
    "papermill": {
     "duration": 5.890516,
     "end_time": "2022-10-08T10:43:19.562248",
     "exception": false,
     "start_time": "2022-10-08T10:43:13.671732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 1s 0us/step\n",
      "219070464/219055592 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model_inception_resnet = InceptionResNetV2(include_top=False, weights='imagenet')\n",
    "model_inception_resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea7e19c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:19.588454Z",
     "iopub.status.busy": "2022-10-08T10:43:19.588025Z",
     "iopub.status.idle": "2022-10-08T10:43:27.054510Z",
     "shell.execute_reply": "2022-10-08T10:43:27.053516Z"
    },
    "papermill": {
     "duration": 7.482344,
     "end_time": "2022-10-08T10:43:27.057179",
     "exception": false,
     "start_time": "2022-10-08T10:43:19.574835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = [Input(shape=(*INPUT_HDR_SHAPE, 3)), Input(shape=(*INPUT_BDL_SHAPE, 3)), Input(shape=(*INPUT_BDR_SHAPE, 3)), Input(shape=(*INPUT_FTR_SHAPE, 3)), Input(shape=(*INPUT_SHAPE, 3))]\n",
    "outputs = [model_inception_resnet(inp) for inp in inputs]\n",
    "outputs = [GlobalAvgPool2D()(out) for out in outputs]\n",
    "model = tf.keras.Model(inputs, outputs, name='Inception-ResNet-4Piece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c632504f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:27.075425Z",
     "iopub.status.busy": "2022-10-08T10:43:27.075023Z",
     "iopub.status.idle": "2022-10-08T10:43:27.109431Z",
     "shell.execute_reply": "2022-10-08T10:43:27.108393Z"
    },
    "papermill": {
     "duration": 0.046995,
     "end_time": "2022-10-08T10:43:27.112643",
     "exception": false,
     "start_time": "2022-10-08T10:43:27.065648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception-ResNet-4Piece\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 250, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 250, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 800, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_resnet_v2 (Functional (None, None, None, 1 54336736    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1536)         0           inception_resnet_v2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1536)         0           inception_resnet_v2[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1536)         0           inception_resnet_v2[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 1536)         0           inception_resnet_v2[3][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 1536)         0           inception_resnet_v2[4][0]        \n",
      "==================================================================================================\n",
      "Total params: 54,336,736\n",
      "Trainable params: 0\n",
      "Non-trainable params: 54,336,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29373c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T10:43:27.130809Z",
     "iopub.status.busy": "2022-10-08T10:43:27.130477Z",
     "iopub.status.idle": "2022-10-08T11:05:41.291748Z",
     "shell.execute_reply": "2022-10-08T11:05:41.290630Z"
    },
    "papermill": {
     "duration": 1334.174077,
     "end_time": "2022-10-08T11:05:41.294995",
     "exception": false,
     "start_time": "2022-10-08T10:43:27.120918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 10:43:27.619179: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-10-08 10:43:44.459994: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-2\n",
      "Batch-3\n",
      "Batch-4\n",
      "Batch-5\n",
      "Batch-6\n",
      "Batch-7\n",
      "Batch-8\n",
      "Batch-9\n",
      "Batch-10\n"
     ]
    }
   ],
   "source": [
    "precompute_ResNet_output = 0\n",
    "for idx in range(len(labels)//1600):\n",
    "    print(f\"Batch-{idx+1}\")\n",
    "    train_generator_precompute = ImageDataGenerator(\n",
    "        df=labels[idx*1600:(idx+1)*1600],\n",
    "        X_col='images',\n",
    "        y_col='label',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        input_size=INPUT_SHAPE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    precompute_ResNet_output = model.predict(train_generator_precompute)\n",
    "    tf.keras.backend.clear_session()\n",
    "    _ = gc.collect()\n",
    "    np.save(f'./train_data_precomp-{idx}.npy', precompute_ResNet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f495bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T11:05:41.323828Z",
     "iopub.status.busy": "2022-10-08T11:05:41.323293Z",
     "iopub.status.idle": "2022-10-08T11:05:41.328297Z",
     "shell.execute_reply": "2022-10-08T11:05:41.327111Z"
    },
    "papermill": {
     "duration": 0.023112,
     "end_time": "2022-10-08T11:05:41.331858",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.308746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fine_tune_data = np.concatenate([np.transpose(np.load(f'./Data/EffNet-4P-train-precompute/train_data_precomp-{idx}.npy'), (1,0,2)) for idx in range(10)])\n",
    "# np.save(f'./Data/EffNet-4P-train-precompute/whole_train_data_precomp.npy', fine_tune_data)\n",
    "# fine_tune_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aeb9e9",
   "metadata": {
    "papermill": {
     "duration": 0.012434,
     "end_time": "2022-10-08T11:05:41.357927",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.345493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The EfficientNetV2L gives a 3D output per image with $1280$ channels which are collapsed using GlobalAveragePooling2D and we get a 1280 representation vector per 4 parts of the image and full image ($4+1=5$) which will be used to train the later extra layers of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fccc5",
   "metadata": {
    "papermill": {
     "duration": 0.013133,
     "end_time": "2022-10-08T11:05:41.384412",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.371279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### On Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0b58e",
   "metadata": {
    "papermill": {
     "duration": 0.012682,
     "end_time": "2022-10-08T11:05:41.410355",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.397673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generating Predictions for the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1e413d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T11:05:41.438765Z",
     "iopub.status.busy": "2022-10-08T11:05:41.438165Z",
     "iopub.status.idle": "2022-10-08T11:05:41.456372Z",
     "shell.execute_reply": "2022-10-08T11:05:41.455431Z"
    },
    "papermill": {
     "duration": 0.034939,
     "end_time": "2022-10-08T11:05:41.458557",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.423618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, X_col, batch_size, input_size=(800, 600), shuffle=True):\n",
    "        self.df = df.copy() # DataFrame consisting image paths of inputs and the labels for the outputs\n",
    "        self.X_col = X_col # Input column, specifying image path, in the DataFrame\n",
    "        self.batch_size = batch_size # Batch Size\n",
    "        self.input_size = input_size # Input Image size\n",
    "        self.shuffle = shuffle # Shuffle Data after each epoch\n",
    "        self.n = len(self.df) # length of the entire data\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        img_arr = img_to_array(load_img(path))\n",
    "        # some other pre-processing / data-augmentation goes here\n",
    "        img_arr = tf.image.resize(img_arr, self.input_size)\n",
    "        img_hdr, img_bdl, img_bdr, img_ftr = img_arr[:250], img_arr[250:-250, :300], img_arr[250:-250, -300:], img_arr[-250:]\n",
    "        return [preprocess_input(img_hdr), preprocess_input(img_bdl), preprocess_input(img_bdr), preprocess_input(img_ftr), preprocess_input(img_arr)]\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        batch_paths = batches[self.X_col]\n",
    "        X_batch_4 = [self.__get_input(path) for path in batch_paths]\n",
    "        X_batch = tf.cast([img[0] for img in X_batch_4], dtype=tf.float32), tf.cast([img[1] for img in X_batch_4], dtype=tf.float32), tf.cast([img[2] for img in X_batch_4], dtype=tf.float32), tf.cast([img[3] for img in X_batch_4], dtype=tf.float32), tf.cast([img[4] for img in X_batch_4], dtype=tf.float32)\n",
    "        return (X_batch, )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X = self.__get_data(batches)\n",
    "        return X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e928d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T11:05:41.486453Z",
     "iopub.status.busy": "2022-10-08T11:05:41.486028Z",
     "iopub.status.idle": "2022-10-08T11:05:41.512389Z",
     "shell.execute_reply": "2022-10-08T11:05:41.511140Z"
    },
    "papermill": {
     "duration": 0.043126,
     "end_time": "2022-10-08T11:05:41.514869",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.471743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>17801</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>17802</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>17803</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>17804</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>17805</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>18696</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>18697</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>18698</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>18699</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>../input/datathonindoml-2022/validation/valida...</td>\n",
       "      <td>18700</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                images     id  label\n",
       "57   ../input/datathonindoml-2022/validation/valida...  17801     -1\n",
       "141  ../input/datathonindoml-2022/validation/valida...  17802     -1\n",
       "777  ../input/datathonindoml-2022/validation/valida...  17803     -1\n",
       "273  ../input/datathonindoml-2022/validation/valida...  17804     -1\n",
       "30   ../input/datathonindoml-2022/validation/valida...  17805     -1\n",
       "..                                                 ...    ...    ...\n",
       "396  ../input/datathonindoml-2022/validation/valida...  18696     -1\n",
       "111  ../input/datathonindoml-2022/validation/valida...  18697     -1\n",
       "817  ../input/datathonindoml-2022/validation/valida...  18698     -1\n",
       "710  ../input/datathonindoml-2022/validation/valida...  18699     -1\n",
       "293  ../input/datathonindoml-2022/validation/valida...  18700     -1\n",
       "\n",
       "[900 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = pd.DataFrame({'images':['../input/datathonindoml-2022/validation/validation/'+name for name in os.listdir('../input/datathonindoml-2022/validation/validation/')]})\n",
    "validation_data['id'] = [name.split('.')[0] for name in os.listdir('../input/datathonindoml-2022/validation/validation/')]\n",
    "validation_data['label'] = -1 # Simply added to prevent re-writing code\n",
    "validation_data.sort_values(by=['id'], inplace=True)\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ff5f04a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T11:05:41.543190Z",
     "iopub.status.busy": "2022-10-08T11:05:41.542509Z",
     "iopub.status.idle": "2022-10-08T11:05:41.549519Z",
     "shell.execute_reply": "2022-10-08T11:05:41.547971Z"
    },
    "papermill": {
     "duration": 0.024093,
     "end_time": "2022-10-08T11:05:41.552234",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.528141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_generator = ImageDataGenerator(\n",
    "    df=validation_data,\n",
    "    X_col='images',\n",
    "    batch_size=30,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69bed91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T11:05:41.589146Z",
     "iopub.status.busy": "2022-10-08T11:05:41.588588Z",
     "iopub.status.idle": "2022-10-08T11:07:03.373951Z",
     "shell.execute_reply": "2022-10-08T11:07:03.372905Z"
    },
    "papermill": {
     "duration": 81.809903,
     "end_time": "2022-10-08T11:07:03.376616",
     "exception": false,
     "start_time": "2022-10-08T11:05:41.566713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_preds = model.predict(valid_generator)\n",
    "valid_preds = np.transpose(np.concatenate([dat[np.newaxis,:,:] for dat in valid_preds]), (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57cd442b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T11:07:03.397124Z",
     "iopub.status.busy": "2022-10-08T11:07:03.396759Z",
     "iopub.status.idle": "2022-10-08T11:07:03.403271Z",
     "shell.execute_reply": "2022-10-08T11:07:03.402360Z"
    },
    "papermill": {
     "duration": 0.018796,
     "end_time": "2022-10-08T11:07:03.405209",
     "exception": false,
     "start_time": "2022-10-08T11:07:03.386413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 5, 1536)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f2f469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T11:07:03.425606Z",
     "iopub.status.busy": "2022-10-08T11:07:03.424857Z",
     "iopub.status.idle": "2022-10-08T11:07:03.648264Z",
     "shell.execute_reply": "2022-10-08T11:07:03.647278Z"
    },
    "papermill": {
     "duration": 0.236111,
     "end_time": "2022-10-08T11:07:03.650769",
     "exception": false,
     "start_time": "2022-10-08T11:07:03.414658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('./whole_validation_data_precomp.npy', valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecede9a2",
   "metadata": {
    "papermill": {
     "duration": 0.008911,
     "end_time": "2022-10-08T11:07:03.669201",
     "exception": false,
     "start_time": "2022-10-08T11:07:03.660290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1451.031766,
   "end_time": "2022-10-08T11:07:06.975394",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-08T10:42:55.943628",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
