{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562cd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import layoutparser as lp\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAvgPool2D, GlobalAvgPool1D, BatchNormalization, MultiHeadAttention, Layer, LayerNormalization, Concatenate, MaxPool1D\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f6798",
   "metadata": {},
   "source": [
    "### SET THE PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e3993",
   "metadata": {},
   "source": [
    "Set the following paths:\n",
    "- `MODEL_PATH`: The directory which contains the trained model weights.\n",
    "- `DATA_PATH`: The directory path which contains the images.\n",
    "- `PREDICTED_LABELS_PATH`: The directory where the predicted labels are to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd0572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './Pretrained-Model'\n",
    "DATA_PATH = './Data/content/data/noise-added'\n",
    "PREDICTED_LABELS_PATH = './Data/content'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13d8db",
   "metadata": {},
   "source": [
    "### SET FEW MORE PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8bb0f",
   "metadata": {},
   "source": [
    "Set the parameters:\n",
    "- `BATCH_SIZE`: Must divide the number of images in the `DATA_PATH` directory.\n",
    "- `CHECKPOINT_EACH`: Must be a multiple of `BATCH_SIZE` and must divide the number of images in the `DATA_PATH` directory.\n",
    "\n",
    "**Example**:\n",
    "Suppose `DATA_PATH` folder contains $140$ images. So, `BATCH_SIZE` can be chosen to be $70$ as it divides the number of images in the `DATA_PATH` folder. `CHECKPOINT_EACH` can be chosen to be $70$ or $140$ (not $210$ or above as $210$ > $140$) ideally it should be greater than `BATCH_SIZE`.\n",
    "\n",
    "Warning:\n",
    "Too high a `BATCH_SIZE` can run you into Memory Issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8e51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 110\n",
    "CHECKPOINT_EACH = 110"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57baf6",
   "metadata": {},
   "source": [
    "Once done, run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1cc70",
   "metadata": {},
   "source": [
    "#### NOTHING TO CHANGE BELOW, SIMPLY RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c538c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_ROI = (400, 300)\n",
    "MAX_ROIS = 100\n",
    "INPUT_SIZE = (800, 600)\n",
    "ROI_PAD = 5\n",
    "FEATURE_DIM = 1536\n",
    "INPUT_SHAPE = (800, 600)\n",
    "INPUT_HDR_SHAPE = INPUT_FTR_SHAPE = (250, 600)\n",
    "INPUT_BDL_SHAPE = INPUT_BDR_SHAPE = (300, 300)\n",
    "POS_ENC_ANGLE_DENO = 10000\n",
    "NUM_HEADS = 4\n",
    "FF_DIM = FEATURE_DIM // 4\n",
    "assert CHECKPOINT_EACH % BATCH_SIZE == 0\n",
    "assert CHECKPOINT_EACH >= BATCH_SIZE\n",
    "checkpnt_i = CHECKPOINT_EACH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d885d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_type_to_num = {\"TextRegion\":1, \"ImageRegion\":2, \"TableRegion\":3, \"MathsRegion\":4, \"SeparatorRegion\":5, \"OtherRegion\":6}\n",
    "\n",
    "def per_document(doc_data, MAX_ROIS=MAX_ROIS):\n",
    "    if (len(doc_data[0]) == 0): \n",
    "        non_roi_data = np.array([[0, 0, 0, 0, 0]]*MAX_ROIS)\n",
    "        return non_roi_data[np.newaxis, :]\n",
    "    x = np.array(doc_data[0])\n",
    "    top_down = np.argsort(x[:, 0])\n",
    "    x = x[top_down]\n",
    "    if x.shape[0] > 100:\n",
    "        x = x[:100]\n",
    "        pad_mask = np.array([[1]*MAX_ROIS])\n",
    "    else:\n",
    "        x = np.pad(x, pad_width=((0,MAX_ROIS-x.shape[0]),(0,0)), constant_values=0)\n",
    "        pad_mask = np.array([[1]*len(doc_data[0])+[0]*(MAX_ROIS-len(doc_data[0]))])\n",
    "    doc = np.concatenate([x, pad_mask.T], axis=-1)\n",
    "    return doc[np.newaxis, :]\n",
    "\n",
    "def ROI_Extractor(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    layout = model_roi_extracter.detect(img)\n",
    "    roi_coords = list()\n",
    "    for block in layout:\n",
    "        roi_coords.append(block.coordinates)\n",
    "    return per_document([roi_coords])\n",
    "\n",
    "def split_4_pieces(image_path):\n",
    "    img_arr = img_to_array(load_img(image_path))\n",
    "    # some other pre-processing / data-augmentation goes here\n",
    "    img_arr = tf.image.resize(img_arr, INPUT_SIZE)\n",
    "    img_hdr, img_bdl, img_bdr, img_ftr = img_arr[:250], img_arr[250:-250, :300], img_arr[250:-250, -300:], img_arr[-250:]\n",
    "    return [preprocess_input(img_hdr)[tf.newaxis,:], preprocess_input(img_bdl)[tf.newaxis,:], preprocess_input(img_bdr)[tf.newaxis,:], preprocess_input(img_ftr)[tf.newaxis,:], preprocess_input(img_arr)[tf.newaxis,:]]\n",
    "\n",
    "\n",
    "def resize_and_pad_with_doc_max_col(img, f_target_height=INPUT_SHAPE_ROI[0], f_target_width=INPUT_SHAPE_ROI[1]):\n",
    "    f_width = img.shape[1]\n",
    "    f_height = img.shape[0]\n",
    "    ratio = np.max([f_width / f_target_width, f_height / f_target_height])\n",
    "    resized_height_float = f_height / ratio\n",
    "    resized_width_float = f_width / ratio\n",
    "    resized_height = tf.cast(\n",
    "        np.floor(resized_height_float), dtype=tf.int32)\n",
    "    resized_width = tf.cast(\n",
    "        np.floor(resized_width_float), dtype=tf.int32)\n",
    "\n",
    "    padding_height = (f_target_height - resized_height_float) / 2\n",
    "    padding_width = (f_target_width - resized_width_float) / 2\n",
    "    f_padding_height = np.floor(padding_height)\n",
    "    f_padding_width = np.floor(padding_width)\n",
    "    p_height = np.max([0, tf.cast(f_padding_height, dtype=tf.int32)])\n",
    "    p_width = np.max([0, tf.cast(f_padding_width, dtype=tf.int32)])\n",
    "    if f_height < 10 or f_width < 10:\n",
    "      img = tf.image.resize_with_pad(img, max(10, f_height), max(10, f_width))\n",
    "    resized_padded_image = tf.image.resize_with_pad(img, f_target_height, f_target_width).numpy()\n",
    "    white_color = np.max(resized_padded_image)\n",
    "    resized_padded_image[:p_height, :] = white_color\n",
    "    resized_padded_image[(f_target_height-p_height-1):, :] = white_color\n",
    "    resized_padded_image[:, :p_width] = white_color\n",
    "    resized_padded_image[:, (f_target_width-p_width-1):] = white_color\n",
    "    return resized_padded_image\n",
    "\n",
    "def generate_roi_info(image_path):\n",
    "    image_data = img_to_array(load_img(image_path))\n",
    "    roi_info = ROI_Extractor(image_path)[0]\n",
    "    return roi_info\n",
    "\n",
    "def split_roi_pieces(image_path):\n",
    "    image_data = img_to_array(load_img(image_path))\n",
    "    roi_data = ROI_Extractor(image_path)[0]\n",
    "    return np.array([preprocess_input(resize_and_pad_with_doc_max_col(image_data[max(0, int(y_top)-ROI_PAD):min(image_data.shape[0], int(y_bottom)+ROI_PAD), max(0, int(x_top)-ROI_PAD):min(image_data.shape[1], int(x_bottom)+ROI_PAD)])) for x_top, y_top, x_bottom, y_bottom, pad_mask in roi_data if pad_mask == 1])\n",
    "\n",
    "def rois_to_feature_vecs(roi_data):\n",
    "    roi_feature_vecs = model_roi.predict(tf.cast(roi_data, dtype=tf.float32))\n",
    "    _ = gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    padded_roi_feature_vecs = np.concatenate([roi_feature_vecs, np.zeros((MAX_ROIS-roi_feature_vecs.shape[0], FEATURE_DIM))])[np.newaxis,:]\n",
    "    return padded_roi_feature_vecs\n",
    "\n",
    "def piece4_to_feature_vecs(pieces):\n",
    "    pieces = [tf.cast(piece, dtype=tf.float32) for piece in pieces]\n",
    "    pieces_feature_vecs = model_4P.predict(pieces)\n",
    "    _ = gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    return np.transpose(np.concatenate([pieces_feature_vecs]), (1,0,2))\n",
    "\n",
    "def pos_enc(max_len=MAX_ROIS, d_model=FEATURE_DIM):\n",
    "    angles = np.arange(max_len)[:, np.newaxis] / np.power(POS_ENC_ANGLE_DENO, 2*(np.arange(d_model)[np.newaxis, :]//2/np.float32(d_model)))\n",
    "    pos_encode = np.zeros((max_len, d_model))\n",
    "    pos_encode[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "    pos_encode[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "    return tf.cast(pos_encode[np.newaxis, :], dtype=tf.float32)\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, kernel_regularizer=l2(5e-5))\n",
    "        self.ffn = keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, mask, training):\n",
    "        attn_output = self.att(inputs, inputs, inputs, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "def ftmodel():\n",
    "    inputs = Input(shape=(5*FEATURE_DIM))\n",
    "    x = Flatten()(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    inputs_roi = Input(shape=(100, FEATURE_DIM))\n",
    "    inputs_roi_mask = Input(shape=(100, 100))\n",
    "    y = inputs_roi + pos_enc()\n",
    "    y = MaxPool1D(strides=4, data_format='channels_first')(inputs_roi)\n",
    "    y = TransformerBlock(y.shape[-1], NUM_HEADS, FF_DIM)(y, inputs_roi_mask)\n",
    "    y = GlobalAvgPool1D()(y)\n",
    "    \n",
    "    x = Concatenate()([x, y])\n",
    "    \n",
    "    top_dropout_rate = 0.3\n",
    "    x = Dropout(top_dropout_rate, name='top_dropout_2')(x)\n",
    "    x = Dense(512, name='top_dense_2', kernel_initializer=\"he_normal\", kernel_regularizer=l2(5e-5), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    outputs = Dense(16, activation='softmax', name='pred', kernel_regularizer=l2(5e-5))(x)\n",
    "\n",
    "    model1 = tf.keras.Model([inputs, inputs_roi, inputs_roi_mask], outputs, name='Inception-ResNet-4Piece-Vision-Transformer')\n",
    "    return model1\n",
    "\n",
    "def generate_mask(roi_data):\n",
    "    mask = np.zeros((1, MAX_ROIS, MAX_ROIS))\n",
    "    mask[0,:roi_data.shape[0], :roi_data.shape[0]] = 1\n",
    "    return mask\n",
    "\n",
    "class ImageDataGenerator:\n",
    "    def __init__(self, df, X_col, roi_info, y_col, batch_size, roi_pad=5, input_size=(800, 600), shuffle=True, base=0):\n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.roi_info = roi_info\n",
    "        self.y_col = y_col \n",
    "        self.batch_size = batch_size\n",
    "        self.roi_pad = roi_pad \n",
    "        self.input_size = input_size \n",
    "        self.shuffle = shuffle \n",
    "        self.n = len(self.df) \n",
    "        self.idx=base \n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        image_data = img_to_array(load_img(path)) \n",
    "        roi_data = self.roi_info[self.idx]\n",
    "        self.idx += 1\n",
    "        return [preprocess_input(resize_and_pad_with_doc_max_col(image_data[max(0, int(y_top)-self.roi_pad):min(image_data.shape[0], int(y_bottom)+self.roi_pad), max(0, int(x_top)-self.roi_pad):min(image_data.shape[1], int(x_bottom)+self.roi_pad)])) for x_top, y_top, x_bottom, y_bottom, pad_mask in roi_data if pad_mask == 1]\n",
    "\n",
    "    def __get_data(self, batches):\n",
    "        batch_paths = batches[self.X_col]\n",
    "        batch_labels = batches[self.y_col]\n",
    "        X_batch = [np.array(self.__get_input(path)) for path in batch_paths]\n",
    "        y_batch = tf.cast(batch_labels, dtype=tf.float32)\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        self.idx = index * self.batch_size\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    \n",
    "class ImageDataGenerator_4P(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, X_col, batch_size, input_size=(800, 600), shuffle=True):\n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n = len(self.df)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        img_arr = img_to_array(load_img(path))\n",
    "        img_arr = tf.image.resize(img_arr, self.input_size)\n",
    "        img_hdr, img_bdl, img_bdr, img_ftr = img_arr[:250], img_arr[250:-250, :300], img_arr[250:-250, -300:], img_arr[-250:]\n",
    "        return [preprocess_input(img_hdr), preprocess_input(img_bdl), preprocess_input(img_bdr), preprocess_input(img_ftr), preprocess_input(img_arr)]\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        batch_paths = batches[self.X_col]\n",
    "        X_batch_4 = [self.__get_input(path) for path in batch_paths]\n",
    "        X_batch = tf.cast([img[0] for img in X_batch_4], dtype=tf.float32), tf.cast([img[1] for img in X_batch_4], dtype=tf.float32), tf.cast([img[2] for img in X_batch_4], dtype=tf.float32), tf.cast([img[3] for img in X_batch_4], dtype=tf.float32), tf.cast([img[4] for img in X_batch_4], dtype=tf.float32)\n",
    "        return (X_batch, )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X = self.__get_data(batches)\n",
    "        return X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "def generate_roi_infos(image_paths):\n",
    "    rois_info = list()\n",
    "    for image_path in tqdm(image_paths):\n",
    "        rois_info.append(generate_roi_info(image_path)[np.newaxis,:])\n",
    "    return np.concatenate(rois_info)\n",
    "\n",
    "def generate_mask_all(roi_data, roi_count):\n",
    "    mask = np.zeros((*roi_data.shape[:2], roi_data.shape[1]))\n",
    "    k = 0\n",
    "    for num_roi in roi_count:\n",
    "        mask[k,:num_roi,:num_roi] = 1\n",
    "        k += 1\n",
    "    return mask\n",
    "\n",
    "def final_model(image_path):\n",
    "    rois = split_roi_pieces(image_path)\n",
    "    pieces = split_4_pieces(image_path)\n",
    "    roi_features = rois_to_feature_vecs(rois)\n",
    "    pieces_features = piece4_to_feature_vecs(pieces)\n",
    "    pieces_features = np.reshape(pieces_features, (1, -1))\n",
    "    mask = generate_mask(roi_features)\n",
    "    out_probs = model_4P_ViT.predict([tf.cast(pieces_features, dtype=tf.float32), tf.cast(roi_features, dtype=tf.float32), tf.cast(mask, dtype=tf.float32)])\n",
    "    _ = gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    pred_label = np.argmax(out_probs, axis=-1)\n",
    "    return pred_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4305f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 23:29:54.476867: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-17 23:29:54.476988: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model_roi_extracter = lp.Detectron2LayoutModel('lp://PrimaLayout/mask_rcnn_R_50_FPN_3x/config',\n",
    "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5],\n",
    "                                 label_map={1:\"TextRegion\", 2:\"ImageRegion\", 3:\"TableRegion\", 4:\"MathsRegion\", 5:\"SeparatorRegion\", 6:\"OtherRegion\"})\n",
    "\n",
    "model_inception_resnet = InceptionResNetV2(include_top=False, weights='imagenet')\n",
    "model_inception_resnet.trainable = False\n",
    "inp = Input(shape=(*INPUT_SHAPE_ROI, 3))\n",
    "out = model_inception_resnet(inp, training=False)\n",
    "output = GlobalAvgPool2D()(out)\n",
    "model_roi = tf.keras.Model(inp, output, name='Inception-ResNet-kPiece')\n",
    "model_roi.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'], optimizer = Adam(learning_rate = 0.0003))\n",
    "\n",
    "inputs = [Input(shape=(*INPUT_HDR_SHAPE, 3)), Input(shape=(*INPUT_BDL_SHAPE, 3)), Input(shape=(*INPUT_BDR_SHAPE, 3)), Input(shape=(*INPUT_FTR_SHAPE, 3)), Input(shape=(*INPUT_SHAPE, 3))]\n",
    "outputs = [model_inception_resnet(inp) for inp in inputs]\n",
    "outputs = [GlobalAvgPool2D()(out) for out in outputs]\n",
    "model_4P = tf.keras.Model(inputs, outputs, name='Inception-ResNet-4Piece')\n",
    "\n",
    "model_4P_ViT = ftmodel()\n",
    "model_4P_ViT.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'], optimizer = Adam(learning_rate = 0.0003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a5d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_path, data_path, pred_path):\n",
    "    data = pd.DataFrame({'images':[os.path.join(data_path, name) for name in os.listdir(data_path)]})\n",
    "    data['id'] = [name.split('.')[0] for name in os.listdir(data_path)]\n",
    "    data.sort_values(by=['id'], inplace=True)\n",
    "    data['label'] = -1\n",
    "    image_paths = list(data['images'])\n",
    "    print('Images found:', len(image_paths))\n",
    "    print('Extracting ROIs from each image...')\n",
    "    roi_infos = generate_roi_infos(image_paths)\n",
    "    prev_crash_i = 0\n",
    "    print('Converting ROIs to feature vectors, some temporary files will be created in current directory...')\n",
    "    precompute_output = list()\n",
    "    roi_generator = ImageDataGenerator(df=data, X_col='images', roi_info=roi_infos, y_col='label', batch_size=BATCH_SIZE, input_size=INPUT_SHAPE_ROI, shuffle=False)\n",
    "    for i in tqdm(range(prev_crash_i, len(image_paths)//BATCH_SIZE)):\n",
    "        batch = roi_generator[i]\n",
    "        batch = [x for x in batch[0] if len(x.shape) == 4]\n",
    "        batch = tf.concat(batch, axis=0)\n",
    "        precompute_output.append(model_roi.predict(batch))\n",
    "        tf.keras.backend.clear_session()\n",
    "        _ = gc.collect()\n",
    "        if (i+1) % checkpnt_i == 0:\n",
    "            precompute_output = tf.concat(precompute_output, axis=0).numpy()\n",
    "            np.save(f'{(i+1)//checkpnt_i}.npy', precompute_output)\n",
    "            precompute_output = list()\n",
    "            del batch\n",
    "    roi_count = [np.sum([roi[-1]==1 for roi in doc]) for doc in roi_infos]\n",
    "    roi_data = list()\n",
    "    for i in range(len(image_paths)// (BATCH_SIZE*checkpnt_i)):\n",
    "        k = 0\n",
    "        batch_data = np.load(f'{i+1}.npy')\n",
    "        batch_roi = roi_count[(i*(BATCH_SIZE*checkpnt_i)):((i+1)*(BATCH_SIZE*checkpnt_i))]\n",
    "        for j in range(BATCH_SIZE*checkpnt_i):\n",
    "            roi_data.append(np.concatenate([batch_data[k:(k+batch_roi[j])], np.zeros((MAX_ROIS-batch_roi[j], FEATURE_DIM))])[np.newaxis,:])\n",
    "            k += batch_roi[j]\n",
    "    roi_data = tf.cast(np.concatenate(roi_data), dtype=tf.float32)\n",
    "    for i in range(1, len(image_paths)//(BATCH_SIZE*checkpnt_i)+1):\n",
    "        os.remove(f'{i}.npy')\n",
    "    print(\"Done.. Extracted ROIs and Generating Feature Vectors...\")\n",
    "    print('Extracting 4+1 pieces from each image and converting to feature vectors...')\n",
    "    pieces_generator = ImageDataGenerator_4P(df=data, X_col='images', batch_size=BATCH_SIZE, shuffle=False)\n",
    "    pieces_data = model_4P.predict(pieces_generator)\n",
    "    pieces_data = tf.cast(np.reshape(np.transpose(np.concatenate([dat[np.newaxis,:,:] for dat in pieces_data]), (1,0,2)), (len(image_paths), -1)), dtype=tf.float32)\n",
    "    print('Loading Trained RoI Vision Transformer Network weights...')\n",
    "    model_4P_ViT.load_weights(os.path.join(model_path, 'auto-Inception-ResNet-FT-model-weight'))\n",
    "    mask = tf.cast(generate_mask_all(roi_data, roi_count), dtype=tf.float32)\n",
    "    print('Predicting Labels...')\n",
    "    out_probs = model_4P_ViT.predict([pieces_data, roi_data, mask])\n",
    "    pred_labels = np.argmax(out_probs, axis=-1)\n",
    "    results = pd.DataFrame({'id':list(data['id']), 'label':pred_labels})\n",
    "    results.to_csv(os.path.join(pred_path, 'predicted_label.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c8fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images found: 880\n",
      "Extracting ROIs from each image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/880 [00:00<?, ?it/s]/Users/rishideychowdhury/Desktop/IndoML22/env/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|█████████████████████████████████████████| 880/880 [12:11<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ROIs to feature vectors, some temporary files will be created in current directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]2022-11-17 23:42:36.762095: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-17 23:42:37.577546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 16s 283ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████▋                                       | 1/8 [00:40<04:45, 40.85s/it]2022-11-17 23:43:22.531441: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 20s 286ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████▎                                 | 2/8 [01:30<04:34, 45.83s/it]2022-11-17 23:44:12.103847: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 18s 295ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▉                            | 3/8 [02:17<03:53, 46.66s/it]2022-11-17 23:44:52.918839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 14s 291ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 4/8 [02:54<02:50, 42.73s/it]2022-11-17 23:45:29.101100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 12s 308ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████▏                | 5/8 [03:28<01:58, 39.60s/it]2022-11-17 23:46:12.472953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 16s 318ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████▊           | 6/8 [04:16<01:24, 42.34s/it]2022-11-17 23:47:04.942920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 18s 317ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████▍     | 7/8 [05:11<00:46, 46.45s/it]2022-11-17 23:48:06.619106: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 21s 322ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [06:14<00:00, 46.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.. Extracted ROIs and Generating Feature Vectors...\n",
      "Extracting 4+1 pieces from each image and converting to feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 23:48:38.382787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 125s 14s/step\n",
      "Loading Trained RoI Vision Transformer Network weights...\n",
      "Predicting Labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 23:50:41.901571: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 3s 94ms/step\n"
     ]
    }
   ],
   "source": [
    "test(MODEL_PATH, DATA_PATH, PREDICTED_LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98cc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
